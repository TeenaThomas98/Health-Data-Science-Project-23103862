---
title: "Analysis to find out the prevelance of SGA and LBW"
author: "Teena Thomas"
date: "2024-02-22"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading necessary library

```{r}
library(haven)
library (survey)
library(sf)
library(tmap)
library(ggplot2)
library(dplyr)
library(survey)
library(rnaturalearth)
library(rnaturalearthdata)
library(tidyverse)
```


# Reading data

```{r}
data <- read_dta("IAKR7EFL.DTA")
head (data)
```


# Descriptive Statistics

## Creating subset of data with the relevant variables

```{r}
# All the relevant variables for the analysis has been included in the data subset
relevant_columns <- c("caseid","v005", "v021", "v022", "v023", "v024", "v012", "v130", "v131","sdist", "v437", "v438", "m18", "m19", "b4", "b0", "s220a", "v201")
```



## Checking the NA values in the subset data



```{r}
# Creating subset of data with the relevant variables
subset_data <- data %>% select(all_of(relevant_columns))

# Calculate the sum of NA values in each column for the subset
null_values_sum_subset <- colSums(is.na(subset_data))

# Print the sum of null values in each column for the subset
print("Sum of Not Applicable values in each column (subset):")
print(null_values_sum_subset)
```


## Checking the special codes in the subset data

```{r}

# Calculate the percentage of "Don't Know" cases for m18
m18_dk_percent <- mean(subset_data$m18 == 8, na.rm = TRUE) * 100
cat("Percentage of 'Don't Know' cases in m18:", round(m18_dk_percent, 2), "%\n")

# Calculate the percentage of "Don't Know" cases for v131
v131_dk_percent <- mean(subset_data$v131 == 998, na.rm = TRUE) * 100
cat("Percentage of 'Don't Know' cases in v131:", round(v131_dk_percent, 2), "%\n")


# Calculate the percentage of special codes for v438
v438_np_percent <- mean(subset_data$v438 == 9994, na.rm = TRUE) * 100
v438_ref_percent <- mean(subset_data$v438 == 9995, na.rm = TRUE) * 100
v438_oth_percent <- mean(subset_data$v438 == 9996, na.rm = TRUE) * 100
cat("Percentage of special codes in v438:\n")
cat("- Not Present (9994):", round(v438_np_percent, 2), "%\n")
cat("- Refused (9995):", round(v438_ref_percent, 2), "%\n")
cat("- Other (9996):", round(v438_oth_percent, 2), "%\n")

# Calculate the percentage of special codes for v437
v437_np_percent <- mean(subset_data$v437 == 9994, na.rm = TRUE) * 100
v437_ref_percent <- mean(subset_data$v437 == 9995, na.rm = TRUE) * 100
v437_oth_percent <- mean(subset_data$v437 == 9996, na.rm = TRUE) * 100
cat("Percentage of special codes in v437:\n")
cat("- Not Present (9994):", round(v437_np_percent, 2), "%\n")
cat("- Refused (9995):", round(v437_ref_percent, 2), "%\n")
cat("- Other (9996):", round(v437_oth_percent, 2), "%\n")
```


## Checking the birth weight data values

```{r}
m19_counts <- data %>%
summarise(
count_9996 = sum(m19 == 9996, na.rm = TRUE),
count_9998 = sum(m19 == 9998, na.rm = TRUE),
)
print(m19_counts)

```

```{r}
m19_counts <- data %>%
  summarise(
    total = sum(!is.na(m19)),
    count_9996 = sum(m19 == 9996, na.rm = TRUE),
    count_9998 = sum(m19 == 9998, na.rm = TRUE)
  ) %>%
  mutate(
    perc_9996 = (count_9996 / total) * 100,
    perc_9998 = (count_9998 / total) * 100
  )

print(m19_counts)

```



```{r}
# Calculate percentages of special codes in m19
m19_counts <- data %>%
  summarise(
    total = sum(!is.na(m19)),
    count_9996 = sum(m19 == 9996, na.rm = TRUE),
    count_9998 = sum(m19 == 9998, na.rm = TRUE)
  ) %>%
  mutate(
    perc_9996 = (count_9996 / total) * 100,
    perc_9998 = (count_9998 / total) * 100,
    perc_missing = ((count_9996 + count_9998) / total) * 100
  )

print(m19_counts)

```

```{r}
# Function to calculate missing information percentage
calc_missing_percentage <- function(data, variable, special_values) {
  total_cases <- sum(!is.na(data[[variable]]))
  missing_cases <- sum(data[[variable]] %in% special_values, na.rm = TRUE)
  missing_percent <- (missing_cases / total_cases) * 100
  return(missing_percent)
}

# Define special values for maternal covariates
special_values_v131 <- c(998)
special_values_v437 <- c(9994, 9995, 9996)
special_values_v438 <- c(9994, 9995, 9996)

# Calculate missing information percentages for maternal covariates
v131_missing_percent <- calc_missing_percentage(data, "v131", special_values_v131)
v437_missing_percent <- calc_missing_percentage(data, "v437", special_values_v437)
v438_missing_percent <- calc_missing_percentage(data, "v438", special_values_v438)

# Print the results
cat("Percentage of missing information in maternal covariates:\n")
cat("- v131 (Don't Know):", round(v131_missing_percent, 2), "%\n")
cat("- v437 (Special Codes):", round(v437_missing_percent, 2), "%\n")
cat("- v438 (Special Codes):", round(v438_missing_percent, 2), "%\n")

```


```{r}
# Define a function to identify missing cases in the covariates
is_missing <- function(row, special_values_v131, special_values_v437, special_values_v438) {
  return(
    row["v131"] %in% special_values_v131 ||
    row["v437"] %in% special_values_v437 ||
    row["v438"] %in% special_values_v438
  )
}

# Apply the function to each row in the dataset
missing_maternal_covariates <- apply(subset_data, 1, is_missing, 
                                     special_values_v131 = special_values_v131,
                                     special_values_v437 = special_values_v437,
                                     special_values_v438 = special_values_v438)

# Calculate the percentage of babies with any missing maternal covariate
total_babies <- nrow(subset_data)
babies_with_missing_covariates <- sum(missing_maternal_covariates, na.rm = TRUE)
percent_missing_covariates <- (babies_with_missing_covariates / total_babies) * 100

# Print the result
cat("Percentage of babies with at least one missing maternal covariate:", round(percent_missing_covariates, 2), "%\n")

```

```{r}
# Load the required libraries
library(knitr)
library(kableExtra)

# Create the data frame
percentage_data <- data.frame(
  `Variable of Interest` = c("Size of child at birth",
                             "Ethnicity",
                             "Women’s height",
                             "Women’s height",
                             "Women’s height",
                             "Women’s weight",
                             "Women’s weight",
                             "Women’s weight",
                             "Birth weight of babies",
                             "Birth weight of babies"),
  `Type of Missing Value` = c("Don't Know",
                              "Don't Know",
                              "Not Present",
                              "Refused",
                              "Other",
                              "Not Present",
                              "Refused",
                              "Refused",
                              "Not weighed at birth",
                              "Don't Know"),
  Percentage = c(1.52, 0.5, 1.65, 0.76, 0.08, 1.65, 0.76, 0.07, 8.31, 1.84),
  check.names = FALSE
)

# Print the formatted table with a bold caption
percentage_data %>%
  kable(format = "html", caption = "<b>Percentage of Various Missing Values</b>") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)

```



## Cleaning the data through complete case analysis


```{r}
unique (subset_data$v437)
```

```{r}
unique (subset_data$v438)
```



```{r}
# Convert the weight values to actual kilograms
subset_data$v437 <- subset_data$v437 / 10

# Convert the height values to actual centimeters
subset_data$v438 <- subset_data$v438 / 10

# Print the first few converted weights and heights to verify
print(head(subset_data$v437))
print(head(subset_data$v438))
```


```{r}
# Replace special codes with NA
cleaned_data <- subset_data %>%
  mutate(
    m18 = na_if(m18, 8),
    v131 = na_if(v131, 998),
    v438 = na_if(v438, 9994),
    v438 = na_if(v438, 9995),
    v438 = na_if(v438, 9996),
    v437 = na_if(v437, 9994),
    v437 = na_if(v437, 9995),
    v437 = na_if(v437, 9996),
    m19 = na_if(m19, 9996),
    m19 = na_if(m19, 9998)
  )
```


```{r}
# Verify that special codes are replaced with NA
null_values_sum_subset <- colSums(is.na(cleaned_data))
print("Sum of NA values in each column (subset):")
print(null_values_sum_subset)
```


```{r}
# Additional checks for percentages of NA values 
m18_dk_percent <- mean(is.na(cleaned_data$m18)) * 100
cat("Percentage of NA values in m18:", round(m18_dk_percent, 2), "%\n")

v131_dk_percent <- mean(is.na(cleaned_data$v131)) * 100
cat("Percentage of NA values in v131:", round(v131_dk_percent, 2), "%\n")

v438_na_percent <- mean(is.na(cleaned_data$v438)) * 100
cat("Percentage of NA values in v438:", round(v438_na_percent, 2), "%\n")

v437_na_percent <- mean(is.na(cleaned_data$v437)) * 100
cat("Percentage of NA values in v437:", round(v437_na_percent, 2), "%\n")

m19_na_percent <- mean(is.na(cleaned_data$m19)) * 100
cat("Percentage of NA values in m19:", round(m19_na_percent, 2), "%\n")

```

```{r}
dataset_dimensions <- dim(cleaned_data)
number_of_rows <- nrow(cleaned_data)
number_of_columns <- ncol(cleaned_data)
print(paste("Number of rows:", number_of_rows))
print(paste("Number of columns:", number_of_columns))
```


```{r}
# Define the relevant columns
categorical_columns <- c( "v130", "v131", "m18","b4","b0")

continuous_columns <- c("v012", "m19", "v437", "v438", "s220a", "v201")
```



```{r}
continuous_summary <- cleaned_data %>%
  select(all_of(continuous_columns)) %>%
  summarise_all(list(mean = ~mean(., na.rm = TRUE), 
                     median = ~median(., na.rm = TRUE), 
                     sd = ~sd(., na.rm = TRUE)))

print(continuous_summary)
```


```{r}
for (col in continuous_columns) {
  print(
    ggplot(cleaned_data, aes_string(x = col)) +
      geom_histogram(binwidth = 30) +
      labs(title = paste("Histogram of", col), x = col, y = "Frequency")
  )
}
```


```{r}
# Box plots for continuous variables by low birth weight status (assume M19 is birth weight)
cleaned_data$LBW <- ifelse(cleaned_data$m19 < 2500, "Low Birth Weight", "Normal Birth Weight")

for (col in continuous_columns) {
  print(
    ggplot(cleaned_data, aes_string(x = "LBW", y = col)) +
      geom_boxplot() +
      labs(title = paste("Box plot of", col, "by LBW status"), x = "LBW status", y = col)
  )
}
```



```{r}
# Assuming b4 = 1 represents Male and b4 = 2 represents Female
cleaned_data$sex <- ifelse(cleaned_data$b4 == 1, "Male", "Female")

ggplot(cleaned_data, aes(x = factor(sex), y = m19)) +
  geom_boxplot(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Box Plot of Birth Weight by Sex of Child", x = "Sex of Child", y = "Birth Weight (g)")
```



```{r}
ggplot(cleaned_data, aes(x = v012, y = m19)) +
  geom_point(color = "blue", alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Scatter Plot of Birth Weight vs. Respondent's Age", x = "Respondent's Age", y = "Birth Weight (g)")

```



# Design Based Approach


```{r}
# Filtered the 9996 and 9998 from m19 values and included only single births and filtered out twins or multiple births

LBW_analysis <- cleaned_data %>%
  filter(b0 == 0) %>%            
  filter(!is.na(m19))            

```



```{r}
m19_counts <- LBW_analysis %>%
  summarise(
    count_NA = sum(is.na(m19))
  )

print(m19_counts)
```

```{r}
LBW_analysis
```


## SGA Analysis using GROW


```{r}
# Load necessary libraries
library(dplyr)


# Coefficients
constant <- 3455.6
median_height <- 163
median_weight <- 64
ethnic_adjustment <- -149.4

# Function to calculate TOW
calculate_TOW <- function(height, weight, parity, sex) {
  htao <- 6.7 * (height - median_height)
  wtao <- 9.1733 * (weight - median_weight) - 0.151 * (weight - median_weight)^2 - 0.001 * (weight - median_weight)^3
  parao <- case_when(
    parity == 1 ~ 101.9,
    parity == 2 ~ 133.7,
    parity == 3 ~ 140.2,
    parity >= 4 ~ 162.7
  )
  sexao <- ifelse(sex == 1, 48.9, -48.9)
  
  TOW <- constant + htao + wtao + ethnic_adjustment + parao + sexao
  return(TOW)
}

# Calculate TOW for each row
LBW_analysis <- LBW_analysis %>%
  rowwise() %>%
  mutate(TOW = calculate_TOW(v438, v437, v201, b4))
```


```{r}
LBW_analysis
```



```{r}
LBW_analysis <- LBW_analysis %>%
  mutate(GA = s220a * 4.33) 

LBW_analysis
```




```{r}
# Proportionality equation to calculate GROW
calculate_GROW <- function(TOW, GA) {
  percentage_weight <- 298.8 - 31.85 * GA + 1.094 * GA^2 - 0.01055 * GA^3
  GROW <- TOW * (percentage_weight / 100)
  return(GROW)
}
```

```{r}
LBW_analysis <- LBW_analysis %>%
  mutate(GROW = calculate_GROW(TOW, GA))

# Display the results
print(LBW_analysis)

```

```{r}
# Calculate the 10th percentile of GROW (GROW * 0.8592)
LBW_analysis <- LBW_analysis %>%
  mutate(GROW_10th_percentile = GROW * 0.8592)

# Label as "SGA" or "Not SGA"
LBW_analysis <- LBW_analysis %>%
  mutate(SGA = ifelse(m19 < GROW_10th_percentile, "SGA", "Not SGA"))

```


```{r}
LBW_analysis
```


```{r}
library(survey)

# Create survey design
survey_design <- svydesign(id = ~v021, strata = ~v022, weights = ~v005, data = LBW_analysis, nest = TRUE)
options(survey.lonely.psu = "adjust")

```




```{r}
# Calculate overall prevalence of SGA
sga_prevalence <- svymean(~factor(SGA, levels = c("SGA", "Not SGA")), design = survey_design, na.rm = TRUE)

# Extract prevalence and standard errors for SGA
sga_prevalence_true <- coef(sga_prevalence)["factor(SGA, levels = c(\"SGA\", \"Not SGA\"))SGA"] * 100
sga_prevalence_se <- SE(sga_prevalence)["factor(SGA, levels = c(\"SGA\", \"Not SGA\"))SGA"] * 100

# Print results
cat("Overall Prevalence of Small for Gestational Age (SGA):", round(sga_prevalence_true, 2), "%\n")
cat("Standard Error:", round(sga_prevalence_se, 2), "%\n\n")

```

```{r}
# Calculate state-level prevalence of SGA
state_sga_prevalence <- svyby(~factor(SGA, levels = c("SGA", "Not SGA")), ~v024, design = survey_design, svymean, na.rm = TRUE)

# Calculate district-level prevalence of SGA
district_sga_prevalence <- svyby(~factor(SGA, levels = c("SGA", "Not SGA")), ~sdist, design = survey_design, svymean, na.rm = TRUE)
```


```{r}
# Renaming and converting columns in state_sga_prevalence
state_sga_prevalence <- state_sga_prevalence %>%
  mutate(
    `factor(SGA, levels = c("SGA", "Not SGA"))SGA` = `factor(SGA, levels = c("SGA", "Not SGA"))SGA` * 100,
    `se.factor(SGA, levels = c("SGA", "Not SGA"))SGA` = `se.factor(SGA, levels = c("SGA", "Not SGA"))SGA` * 100
  ) %>%
  rename(
    `prevalence of SGA` = `factor(SGA, levels = c("SGA", "Not SGA"))SGA`,
    `standard error of SGA` = `se.factor(SGA, levels = c("SGA", "Not SGA"))SGA`
  )

# Renaming and converting columns in district_sga_prevalence
district_sga_prevalence <- district_sga_prevalence %>%
  mutate(
    `factor(SGA, levels = c("SGA", "Not SGA"))SGA` = `factor(SGA, levels = c("SGA", "Not SGA"))SGA` * 100,
    `se.factor(SGA, levels = c("SGA", "Not SGA"))SGA` = `se.factor(SGA, levels = c("SGA", "Not SGA"))SGA` * 100
  ) %>%
  rename(
    `prevalence of SGA` = `factor(SGA, levels = c("SGA", "Not SGA"))SGA`,
    `standard error of SGA` = `se.factor(SGA, levels = c("SGA", "Not SGA"))SGA`
  )

# Print results
print(state_sga_prevalence)
print(district_sga_prevalence)

```


```{r}
library(writexl)
write_xlsx(district_sga_prevalence, path = "GROW_district_sga_prevalence.xlsx")
```

```{r}
# Load necessary libraries
library(dplyr)
library(sf)
library(ggplot2)
library(viridis)
library(leaflet)
library(htmltools)

# Load the state-level shapefile from GADM
india_states <- st_read("gadm41_IND_1.json")

# Check the unique state names in the shapefile
unique_states <- unique(india_states$NAME_1)
print(unique_states)

# Create a mapping for the state names
state_mapping <- data.frame(
  v024 = c(1:24, 25, 25, 27:36),
  state_name = c("JammuandKashmir", "HimachalPradesh", "Punjab", "Chandigarh", 
                 "Uttarakhand", "Haryana", "NCTofDelhi", "Rajasthan", "UttarPradesh", 
                 "Bihar", "Sikkim", "ArunachalPradesh", "Nagaland", "Manipur", 
                 "Mizoram", "Tripura", "Meghalaya", "Assam", "WestBengal", "Jharkhand", 
                 "Odisha", "Chhattisgarh", "MadhyaPradesh", "Gujarat", 
                 "DadraandNagarHaveliandDamanandDiu", "DadraandNagarHaveliandDamanandDiu", "Maharashtra", "AndhraPradesh", 
                 "Karnataka", "Goa", "Lakshadweep", "Kerala", "TamilNadu", 
                 "Puducherry", "AndamanandNicobar", "Telangana"),
  stringsAsFactors = FALSE
)

# Join this mapping to the SGA prevalence data
state_sga_prevalence <- state_sga_prevalence %>%
  mutate(v024 = ifelse(v024 == 25, 25, v024)) %>%
  left_join(state_mapping, by = "v024") %>%
  select(state_name, `prevalence of SGA`, `standard error of SGA`)

# Combine Dadra and Nagar Haveli and Daman and Diu in the spatial data
india_states <- india_states %>%
  mutate(NAME_1 = ifelse(NAME_1 %in% c("DadraandNagarHaveli", "DamanandDiu"), "DadraandNagarHaveliandDamanandDiu", NAME_1))

# Combine prevalence data for Dadra and Nagar Haveli and Daman and Diu
state_sga_prevalence <- state_sga_prevalence %>%
  group_by(state_name) %>%
  summarize(prevalence = mean(`prevalence of SGA`, na.rm = TRUE), se = mean(`standard error of SGA`, na.rm = TRUE))

# Join the standardized state names with the spatial data
india_states <- india_states %>%
  left_join(state_sga_prevalence, by = c("NAME_1" = "state_name"))

# Remove Ladakh from the dataset because Ladakh is not there in the NFHS data
india_states <- india_states %>%
  filter(NAME_1 != "Ladakh")

# Plot the map
ggplot(india_states) +
  geom_sf(aes(fill = prevalence)) +
  scale_fill_viridis_c(option = "plasma", name = "Prevalence (%)", direction = -1, limits = c(0, 60)) +
  labs(title = "Prevalence of Small for Gestational Age by State in India",
       subtitle = "Based on GROW Standard",
       fill = "Prevalence (%)") +
  theme_minimal() 

```


```{r}
library(leaflet)
library(dplyr)
library(htmltools)
library(htmlwidgets)

# Calculate the upper and lower bounds of the confidence intervals
india_states <- india_states %>%
  mutate(
    lower_bound = prevalence - 1.96 * se,
    upper_bound = prevalence + 1.96 * se
  )

# Create labels with HTML formatting
india_states$label <- paste0(
  "State: <strong>", india_states$NAME_1, "</strong><br>",
  "Prevalence: <strong>", round(india_states$prevalence, 2), "%</strong><br>",
  "95% CI: <strong>", round(india_states$lower_bound, 2), "% - ", round(india_states$upper_bound, 2), "%</strong>"
)

# Wrap label content with HTML function
india_states$label <- lapply(india_states$label, htmltools::HTML)

# Define the HTML for title and subtitle
map_title <- tags$h3("Prevalence of Small for Gestational Age in India")
map_subtitle <- tags$p("Based on GROW Standard")

# Plot the interactive map
map_GROW <- leaflet(india_states) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~colorQuantile("Viridis", prevalence)(prevalence),
    weight = 1,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    label = ~label,
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto"
    ),
    highlightOptions = highlightOptions(
      color = "white",
      weight = 2,
      bringToFront = TRUE
    ),
    options = leafletOptions(
      title = map_title,  # Add title
      subtitle = map_subtitle  # Add subtitle
    )
  )

 

# Print the map to view it in the RStudio viewer
print(map_GROW)

# Save the map as an HTML file
saveWidget(map_GROW, file = "India_sga_grow_prevalence_map.html")

```

ed

## SGA Analysis using INTERGROWTH


```{r}
library(readxl)
library(writexl)
library(dplyr)

# Convert gestational age from months to weeks and days
LBW_analysis <- LBW_analysis %>%
  mutate(
    GA_weeks = floor(GA),    # Extract whole weeks
    GA_days = round((GA - GA_weeks) * 7),  # Convert remaining fraction to days
    Gestational_age = paste(GA_weeks, GA_days, sep = "+")  # Format as "weeks+days"
  )
```

```{r}
LBW_analysis
```



```{r}
# Read the Excel template
excel_template <- read_excel("Intergrowth.xlsx", sheet = 1)
```


```{r}
# Prepare the data frame to match the Excel template

excel_data <- data.frame(
  `ID` = LBW_analysis$caseid,
  `Gestational age (weeks+days)` = LBW_analysis$Gestational_age,
  `EFW (g)` = LBW_analysis$m19,
  `v005` = LBW_analysis$v005,
  `v021` = LBW_analysis$v021,
  `v022` = LBW_analysis$v022,
  `v023` = LBW_analysis$v023,
  `v024` = LBW_analysis$v024,
  `v012` = LBW_analysis$v012,
  `v130` = LBW_analysis$v130,
  `v131` = LBW_analysis$v131,
  `sdist` = LBW_analysis$sdist,
  `v437` = LBW_analysis$v437,
  `v438` = LBW_analysis$v438,
  `m18` = LBW_analysis$m18,
  `m19` = LBW_analysis$m19,
  `b4` = LBW_analysis$b4,
  `b0` = LBW_analysis$b0,
  `s220a` = LBW_analysis$s220a,
  `v201` = LBW_analysis$v201,
  `TOW` = LBW_analysis$TOW,
  `GROW` = LBW_analysis$GROW,
  `GROW_10th_percentile` = LBW_analysis$GROW_10th_percentile,
  `GROW_SGA` = LBW_analysis$SGA
)


# Assuming the template starts at row 2 (row 1 being the header)
# Adjust the row number if your template structure is different
start_row <- 4

# Write the data to the Excel template
write_xlsx(excel_data, "Intergrowth_Updates.xlsx")

```


```{r}
# Load necessary libraries
library(readxl)
library(dplyr)

# Read the Excel file
intergrowth_data <- read_excel("Intergrowth_SGA.xlsx")

# Calculate SGA status
intergrowth_data <- intergrowth_data %>%
  mutate(Intergrowth_SGA = ifelse(centile < 10, "SGA", "Not SGA"))

# View the updated data with SGA status
print(intergrowth_data)

# Save the updated data to a new Excel file
write_xlsx(intergrowth_data, "Intergrowth_results_with_SGA.xlsx")

```


```{r}
intergrowth_data <- read_excel("Intergrowth_results_with_SGA.xlsx", sheet = 1)
```

```{r}
intergrowth_data
```


```{r}

# Create survey design
survey_design <- svydesign(id = ~v021, strata = ~v022, weights = ~v005, data = intergrowth_data, nest = TRUE)
options(survey.lonely.psu = "adjust")

# Calculate overall prevalence of SGA
Intergrowth_sga_prevalence <- svymean(~factor(Intergrowth_SGA, levels = c("SGA", "Not SGA")), design = survey_design, na.rm = TRUE)

# Extract prevalence and standard errors for SGA
Intergrowth_sga_prevalence_true <- coef(Intergrowth_sga_prevalence)["factor(Intergrowth_SGA, levels = c(\"SGA\", \"Not SGA\"))SGA"] * 100
Intergrowth_sga_prevalence_se <- SE(Intergrowth_sga_prevalence)["factor(Intergrowth_SGA, levels = c(\"SGA\", \"Not SGA\"))SGA"] * 100

# Print results
cat("Overall Prevalence of Small for Gestational Age (SGA):", round(Intergrowth_sga_prevalence_true, 2), "%\n")
cat("Standard Error:", round(Intergrowth_sga_prevalence_se, 2), "%\n\n")
```

```{r}
# Calculate state-level prevalence of Intergrowth SGA
state_intergrowth_sga_prevalence <- svyby(~factor(Intergrowth_SGA, levels = c("SGA", "Not SGA")), ~v024, design = survey_design, svymean, na.rm = TRUE)

# Renaming and converting columns in state_intergrowth_sga_prevalence
state_intergrowth_sga_prevalence <- state_intergrowth_sga_prevalence %>%
  mutate(
    `factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA` = `factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA` * 100,
    `se.factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA` = `se.factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA` * 100
  ) %>%
  rename(
    `prevalence of SGA` = `factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA`,
    `standard error of SGA` = `se.factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA`
  )



# Calculate district-level prevalence of SGA
district_intergrowth_sga_prevalence <- svyby(~factor(Intergrowth_SGA, levels = c("SGA", "Not SGA")), ~sdist, design = survey_design, svymean, na.rm = TRUE)


# Renaming and converting columns in district_sga_prevalence
district_intergrowth_sga_prevalence <- district_intergrowth_sga_prevalence %>%
  mutate(
    `factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA` = `factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA` * 100,
    `se.factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA` = `se.factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA` * 100
  ) %>%
  rename(
    `prevalence of SGA` = `factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA`,
    `standard error of SGA` = `se.factor(Intergrowth_SGA, levels = c("SGA", "Not SGA"))SGA`
  )

# Print results
print(state_intergrowth_sga_prevalence)
print(district_intergrowth_sga_prevalence)

```


```{r}
write_xlsx(district_intergrowth_sga_prevalence, path = "Intergrowth_district_sga_prevalence.xlsx")
```




```{r}
# Join this mapping to the SGA prevalence data
state_intergrowth_sga_prevalence <- state_intergrowth_sga_prevalence %>%
  mutate(v024 = ifelse(v024 == 25, 25, v024)) %>%
  left_join(state_mapping, by = "v024") %>%
  select(state_name, `prevalence of SGA`, `standard error of SGA`)

# Combine Dadra and Nagar Haveli and Daman and Diu in the spatial data
india_states <- india_states %>%
  mutate(NAME_1 = ifelse(NAME_1 %in% c("DadraandNagarHaveli", "DamanandDiu"), "DadraandNagarHaveliandDamanandDiu", NAME_1))

# Combine prevalence data for Dadra and Nagar Haveli and Daman and Diu
state_intergrowth_sga_prevalence <- state_intergrowth_sga_prevalence %>%
  group_by(state_name) %>%
  summarize(prevalence = mean(`prevalence of SGA`, na.rm = TRUE), se = mean(`standard error of SGA`, na.rm = TRUE))

# Join the standardized state names with the spatial data
india_states <- india_states %>%
  left_join(state_intergrowth_sga_prevalence, by = c("NAME_1" = "state_name"))

# Remove Ladakh from the dataset because Ladakh is not there in the NFHS data
india_states <- india_states %>%
  filter(NAME_1 != "Ladakh")
```



```{r}
# Plot the map
ggplot(india_states) +
  geom_sf(aes(fill = prevalence.y)) +
  scale_fill_viridis_c(option = "plasma", name = "Prevalence (%)", direction = -1, limits = c(0, 60)) +
  labs(
    title = "Prevalence of Small for Gestational Age (SGA) by State in India",
    subtitle = "Based on INTERGROWTH-21st Standard",
    fill = "Prevalence (%)"
  ) +
  theme_minimal()

```

```{r}

# Calculate the upper and lower bounds of the confidence intervals for INTERGROWTH data
india_states <- india_states %>%
  mutate(
    lower_bound_intergrowth = prevalence.y - 1.96 * se.y,
    upper_bound_intergrowth = prevalence.y + 1.96 * se.y
  )

# Create labels with HTML formatting for INTERGROWTH data
india_states$label_intergrowth <- paste0(
  "State: <strong>", india_states$NAME_1, "</strong><br>",
  "Prevalence: <strong>", round(india_states$prevalence.y, 2), "%</strong><br>",
  "95% CI: <strong>", round(india_states$lower_bound_intergrowth, 2), "% - ", round(india_states$upper_bound_intergrowth, 2), "%</strong>"
)

# Wrap label content with HTML function
india_states$label_intergrowth <- lapply(india_states$label_intergrowth, htmltools::HTML)

# Plot the interactive map for INTERGROWTH data
map_INTR <- leaflet(india_states) %>%
  addTiles() %>%
  addPolygons(
    fillColor = ~colorQuantile("Viridis", prevalence.y)(prevalence.y),
    weight = 1,
    opacity = 1,
    color = "white",
    dashArray = "3",
    fillOpacity = 0.7,
    label = ~label_intergrowth,
    labelOptions = labelOptions(
      style = list("font-weight" = "normal", padding = "3px 8px"),
      textsize = "15px",
      direction = "auto"
    ),
    highlightOptions = highlightOptions(
      color = "white",
      weight = 2,
      bringToFront = TRUE
    )
  ) %>%
  addLegend(
    pal = colorQuantile("Viridis", india_states$prevalence.y),
    values = ~prevalence.y,
    opacity = 0.7,
    title = "Prevalence (%)",
    position = "bottomright"
  )

# Print the map to view it in the RStudio viewer
print(map_INTR)

# Save the map as an HTML file
saveWidget(map_INTR, file = "India_sga_Intr_prevalence_map.html")


```




## Finding out LBW


## Creating the survey design for the calculation of Low Birth Weight


```{r}
head (LBW_analysis)
```




```{r}
# Create survey design
survey_design <- svydesign(id = ~v021, strata = ~v022, weights = ~v005, data = LBW_analysis, nest = TRUE)

options(survey.lonely.psu = "adjust")

# Calculate overall prevalence of low birth weight (less than 2500 grams)
low_birth_weight <- svymean(~I(m19 < 2500), design = survey_design, na.rm = TRUE)

# Extract prevalence and standard errors
low_birth_weight_true <- coef(low_birth_weight)["I(m19 < 2500)TRUE"] * 100
low_birth_weight_se <- SE(low_birth_weight)["I(m19 < 2500)TRUE"] * 100
```


```{r}
# Calculate state-level prevalence of low birth weight
state_prevalence_true <- svyby(~I(m19 < 2500), ~v024, design = survey_design, svymean, na.rm = TRUE)

# Calculate district-level prevalence of low birth weight
district_prevalence_true <- svyby(~I(m19 < 2500), ~sdist, design = survey_design, svymean, na.rm = TRUE)
```


```{r}
state_prevalence_true
district_prevalence_true
```


```{r}
# Convert proportions to percentages in state_prevalence_true
state_prevalence_true <- state_prevalence_true %>%
  mutate(
    `I(m19 < 2500)FALSE` = `I(m19 < 2500)FALSE` * 100,
    `I(m19 < 2500)TRUE` = `I(m19 < 2500)TRUE` * 100,
    `se.I(m19 < 2500)FALSE` = `se.I(m19 < 2500)FALSE` * 100,
    `se.I(m19 < 2500)TRUE` = `se.I(m19 < 2500)TRUE` * 100
  )

# Convert proportions to percentages in district_prevalence_true
district_prevalence_true <- district_prevalence_true %>%
  mutate(
    `I(m19 < 2500)FALSE` = `I(m19 < 2500)FALSE` * 100,
    `I(m19 < 2500)TRUE` = `I(m19 < 2500)TRUE` * 100,
    `se.I(m19 < 2500)FALSE` = `se.I(m19 < 2500)FALSE` * 100,
    `se.I(m19 < 2500)TRUE` = `se.I(m19 < 2500)TRUE` * 100
  )

```


```{r}
state_prevalence_true
district_prevalence_true
```


```{r}
write_xlsx(district_prevalence_true, path = "LBW_district_sga_prevalence.xlsx")
```




```{r}
# Print results
cat("Overall Prevalence of Low Birth Weight (LBW):", round(low_birth_weight_true, 2), "%\n")
cat("Standard Error:", round(low_birth_weight_se, 2), "%\n\n")
```




## Creating Maps for low birth weight prevelance at the state level

```{r}
# Loaded state-level shapefile from GADM
india_states <- st_read("gadm41_IND_1.json")
```

```{r}
unique_states <- unique(india_states$NAME_1)
print(unique_states)
```


```{r}
# Created a mapping for the state names
state_mapping <- data.frame(
  v024 = c(1:24, 25, 25, 27:36),
  state_name = c("JammuandKashmir", "HimachalPradesh", "Punjab", "Chandigarh", 
                 "Uttarakhand", "Haryana", "NCTofDelhi", "Rajasthan", "UttarPradesh", 
                 "Bihar", "Sikkim", "ArunachalPradesh", "Nagaland", "Manipur", 
                 "Mizoram", "Tripura", "Meghalaya", "Assam", "WestBengal", "Jharkhand", 
                 "Odisha", "Chhattisgarh", "MadhyaPradesh", "Gujarat", 
                 "DadraandNagarHaveliandDamanandDiu", "DadraandNagarHaveliandDamanandDiu", "Maharashtra", "AndhraPradesh", 
                 "Karnataka", "Goa", "Lakshadweep", "Kerala", "TamilNadu", 
                 "Puducherry", "AndamanandNicobar", "Telangana"),
  stringsAsFactors = FALSE
)

# Combining Dadra and Nagar Haveli and Daman and Diu in the prevalence data because this is mentioned as one state in the NFHS dataset and as seperate in the GADM file
state_prevalence_true <- state_prevalence_true %>%
  mutate(v024 = ifelse(v024 == 25, 25, v024))

# Join this mapping to the prevalence_by_state data
state_prevalence_true <- state_prevalence_true %>%
  left_join(state_mapping, by = "v024") %>%
  select(state_name, `I(m19 < 2500)TRUE`, `se.I(m19 < 2500)TRUE`) %>%
  rename(prevalence = `I(m19 < 2500)TRUE`, se = `se.I(m19 < 2500)TRUE`)

# Combined Dadra and Nagar Haveli and Daman and Diu in the spatial data
india_states <- india_states %>%
  mutate(NAME_1 = ifelse(NAME_1 %in% c("DadraandNagarHaveli", "DamanandDiu"), "DadraandNagarHaveliandDamanandDiu", NAME_1))

# Combine prevalence data for Dadra and Nagar Haveli and Daman and Diu
state_prevalence_true <- state_prevalence_true %>%
  group_by(state_name) %>%
  summarize(prevalence = mean(prevalence, na.rm = TRUE), se = mean(se, na.rm = TRUE))

# Join the standardized state names with the spatial data
india_states <- india_states %>%
  left_join(state_prevalence_true, by = c("NAME_1" = "state_name"))

# Removed Ladakh from the dataset because Ladakh is not there in the NFHS data
india_states <- india_states %>%
  filter(NAME_1 != "Ladakh")
```


```{r}
# Plot the map
ggplot(india_states) +
  geom_sf(aes(fill = prevalence)) +
  scale_fill_viridis_c(option = "plasma", name = "Prevalence (%)", direction = -1, limits = c(0, 60)) +
  labs(title = "Low Birth Weight Prevalence by State in India",
       fill = "Prevalence (%)") +
  theme_minimal()

```



```{r}
# Calculate the upper and lower bounds of the confidence intervals
india_states <- india_states %>%
mutate(
lower_bound = prevalence - 1.96 * se,
upper_bound = prevalence + 1.96 * se
)
```



```{r}
library(leaflet)
library(htmltools)


# Create labels with HTML formatting
india_states$label <- paste0(
  "State: <strong>", india_states$NAME_1, "</strong><br>",
  "Prevalence: <strong>", round(india_states$prevalence, 2), "%</strong><br>",
  "95% CI: <strong>", round(india_states$lower_bound, 2), "% - ", round(india_states$upper_bound, 2), "%</strong>"
)

# Wrap label content with HTML function
india_states$label <- lapply(india_states$label, htmltools::HTML)


map_lbw <- leaflet(india_states) %>%
addTiles() %>%
addPolygons(
fillColor = ~colorQuantile("Viridis", prevalence)(prevalence),
weight = 1,
opacity = 1,
color = "white",
dashArray = "3",
fillOpacity = 0.7,
label = ~label,
labelOptions = labelOptions(
style = list("font-weight" = "normal", padding = "3px 8px"),
textsize = "15px",
direction = "auto"
),
highlightOptions = highlightOptions(
color = "white",
weight = 2,
bringToFront = TRUE
)
)

# Print the map to view it in the RStudio viewer
print(map_lbw )

# Save the map as an HTML file
saveWidget(map_lbw , file = "India_LBW_prevalence_map.html")
```














































































